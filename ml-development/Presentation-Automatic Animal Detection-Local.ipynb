{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2986b81c",
   "metadata": {
    "id": "2986b81c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Automatic Animal Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da258cc",
   "metadata": {
    "id": "4da258cc"
   },
   "source": [
    "# Manual Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480da0e",
   "metadata": {
    "id": "7480da0e"
   },
   "source": [
    "We collect 200 to 400 images per week.\n",
    "\n",
    "Human annotation is laborious, automatic detection of animals in images or videos reduces the time taken.\n",
    "\n",
    "Also, if we are at larger scales say collection of thousands, tens of thousands or hundred of thousands of images manual annotation will become unreasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794afd",
   "metadata": {
    "id": "86794afd"
   },
   "source": [
    "# Automatic Animal Detection in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c14f3f",
   "metadata": {
    "id": "33c14f3f"
   },
   "source": [
    "70 % of the images with animals have either an impala or a zebra\n",
    "\n",
    "We could also do automatic false trigger or non-animal trigger detection since 60% to 80% of the raw unpublished data  was either a false trigger or triggered by a human , birds or even insects.\n",
    "\n",
    "The purpose here is to locate the animals in images and videos, detect which animal it is then verify.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f19b9",
   "metadata": {
    "id": "815f19b9"
   },
   "outputs": [],
   "source": [
    "#file and folder libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#system libraries\n",
    "import os\n",
    "os.makedirs('output', exist_ok = True)\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b19ad-8c68-4d13-a9e9-1c1c3047153d",
   "metadata": {
    "id": "3d6b19ad-8c68-4d13-a9e9-1c1c3047153d"
   },
   "outputs": [],
   "source": [
    "#this is a open source pretrained model\n",
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yU0Nb-5nH8x0",
   "metadata": {
    "id": "yU0Nb-5nH8x0"
   },
   "outputs": [],
   "source": [
    "#if running on colab\n",
    "#!git clone https://github.com/DeKUT-DSAIL/ieee-africon-2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961ac8e",
   "metadata": {
    "id": "e961ac8e"
   },
   "outputs": [],
   "source": [
    "#load animal detection model\n",
    "\n",
    "#Locally Run\n",
    "model = torch.hub.load(r'yolov5', 'custom', path=r'models/lasst.pt', source='local',force_reload=True)\n",
    "\n",
    "#Run in Colab\n",
    "#model = torch.hub.load(r'yolov5', 'custom', path=r'/content/ieee-africon-2023/ml-development/models/lasst.pt', source='local',force_reload=True)\n",
    "print('Detection model has loaded')\n",
    "\n",
    "#Set the confidence which you require from the model\n",
    "model.conf = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585e697-d3f8-4bc5-80ee-7c03f7f7a33f",
   "metadata": {
    "id": "8585e697-d3f8-4bc5-80ee-7c03f7f7a33f"
   },
   "outputs": [],
   "source": [
    "#Run Locally\n",
    "def detect_and_save_custom(file):\n",
    "    results = model('dataset/images/'+file+'.jpg')\n",
    "    print(results)\n",
    "    %matplotlib inline\n",
    "    pred = np.squeeze(results.render())\n",
    "    plt.imshow(pred)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.imsave('output/'+file+'_detected.jpg',pred)\n",
    "\n",
    "# Run in Colab\n",
    "# def detect_and_save_custom(file):\n",
    "#     results = model('/content/ieee-africon-2023/ml-development/dataset/images/'+file+'.jpg')\n",
    "#     print(results)\n",
    "#     %matplotlib inline\n",
    "#     pred = np.squeeze(results.render())\n",
    "#     plt.imshow(pred)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "#     plt.imsave('output/'+file+'_detected.jpg',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199565b",
   "metadata": {
    "id": "7199565b"
   },
   "outputs": [],
   "source": [
    "detect_and_save_custom('impala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7af77",
   "metadata": {
    "id": "1fb7af77"
   },
   "outputs": [],
   "source": [
    "detect_and_save_custom('tortoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5076a63",
   "metadata": {
    "id": "c5076a63"
   },
   "outputs": [],
   "source": [
    "detect_and_save_custom('waterbuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db01ef5",
   "metadata": {
    "id": "6db01ef5"
   },
   "outputs": [],
   "source": [
    "detect_and_save_custom('impalas-warthogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d468b3",
   "metadata": {
    "id": "41d468b3"
   },
   "source": [
    "## Automatic detection on multiple images\n",
    "\n",
    "- It took 2 weeks to manually annotate 8554 images, a rate of 25 images per hour.\n",
    "\n",
    "- Automatically it takes about two hours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc482a8-faca-44be-8191-47d934a77285",
   "metadata": {
    "id": "2dc482a8-faca-44be-8191-47d934a77285"
   },
   "outputs": [],
   "source": [
    "!python3 yolo-inference.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
