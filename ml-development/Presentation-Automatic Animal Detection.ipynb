{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2986b81c",
   "metadata": {},
   "source": [
    "# Automatic Animal Detection\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/DeKUT-DSAIL/ieee-africon-2023/blob/main/ml-development/Presentation-Automatic%20Animal%20Detection.ipynb\">\r\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\r\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da258cc",
   "metadata": {},
   "source": [
    "# Manual Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480da0e",
   "metadata": {},
   "source": [
    "We collect 200 to 400 images per week.\n",
    "\n",
    "Human annotation is laborious, automatic detection of animals in images or videos reduces the time taken.\n",
    "\n",
    "Also, if we are at larger scales say collection of thousands, tens of thousands or hundred of thousands of images manual annotation will become unreasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794afd",
   "metadata": {},
   "source": [
    "# Automatic Animal Detection in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c14f3f",
   "metadata": {},
   "source": [
    "70 % of the images with animals have either an impala or a zebra \n",
    "\n",
    "We could also do automatic false trigger or non-animal trigger detection since 60% to 80% of the raw unpublished data  was either a false trigger or triggered by a human , birds or even insects. \n",
    "\n",
    "The purpose here is to locate the animals in images and videos, detect which animal it is then verify.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file and folder libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#system libraries\n",
    "import os\n",
    "os.makedirs('output', exist_ok = True)\n",
    "from datetime import datetime\n",
    "\n",
    "#Mapping libraries\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b19ad-8c68-4d13-a9e9-1c1c3047153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a open source pretrained model\n",
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load animal detection model\n",
    "#model = torch.hub.load('ultralytics/yolov5', 'custom', path=r'models/lasst.pt',verbose=False,source='local')\n",
    "model = torch.hub.load(r'yolov5', 'custom', path=r'models/lasst.pt', source='local',force_reload=True)\n",
    "print('Detection model has loaded')\n",
    "\n",
    "#Set the confidence which you require from the model\n",
    "model.conf = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585e697-d3f8-4bc5-80ee-7c03f7f7a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_save_custom(file):\n",
    "    results = model('dataset/images/'+file+'.jpg')\n",
    "    print(results)\n",
    "    %matplotlib inline\n",
    "    pred = np.squeeze(results.render())\n",
    "    plt.imshow(pred)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.imsave('output/'+file+'_detected.jpg',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c3c47-b2e1-49d5-84a5-e6f1dfd0dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(results.pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_save_custom('impala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_save_custom('tortoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5076a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_save_custom('waterbuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db01ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_save_custom('impalas-warthogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d468b3",
   "metadata": {},
   "source": [
    "## Automatic detection on multiple images\n",
    "\n",
    "- It took 2 weeks to manually annotate 8554 images, a rate of 25 images per hour.\n",
    "\n",
    "- Automatically it takes about two hours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc482a8-faca-44be-8191-47d934a77285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
